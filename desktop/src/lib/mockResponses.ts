// FALLBACK: Mock response used when Tauri backend is unavailable (browser dev mode)
import { SupportedLanguage, detectLanguage } from "./detectLanguage";

interface LocalizedMockResponse {
  pattern: RegExp;
  responses: Record<SupportedLanguage, string[]>;
}

const mockResponses: LocalizedMockResponse[] = [
  {
    // Greetings - all languages
    pattern:
      /\b(hello|hi|hey|bonjour|salut|hola|hallo|olÃ¡|ciao|ã“ã‚“ã«ã¡ã¯|ì•ˆë…•|ä½ å¥½|Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚|Ù…Ø±Ø­Ø¨Ø§|à¤¨à¤®à¤¸à¥à¤¤à¥‡)\b/iu,
    responses: {
      en: [
        "Hello! I'm your local ARIA assistant, running entirely on your machine with BitNet inference. How can I help you today?\n\nI can assist with:\n- **Understanding ARIA Protocol** and decentralized AI\n- **Model performance** benchmarks and optimization\n- **Technical questions** about 1-bit LLMs\n- **General conversation** and brainstorming",
        "Hey there! Welcome to ARIA's local AI assistant. I'm powered by BitNet and running 100% offline on your hardware â€” no data leaves your device.\n\nWhat would you like to explore today?",
        "Hi! I'm ARIA's on-device assistant. Everything runs locally with **zero cloud dependency**. Ask me anything about decentralized AI, BitNet models, or just chat freely!",
      ],
      fr: [
        "Bonjour ! Je suis votre assistant ARIA local, fonctionnant entiÃ¨rement sur votre machine avec l'infÃ©rence BitNet. Comment puis-je vous aider aujourd'hui ?\n\nJe peux vous aider avec :\n- **Comprendre le protocole ARIA** et l'IA dÃ©centralisÃ©e\n- **Performances des modÃ¨les** et optimisation\n- **Questions techniques** sur les LLM 1-bit\n- **Conversation gÃ©nÃ©rale** et brainstorming",
        "Salut ! Bienvenue sur l'assistant IA local d'ARIA. Je fonctionne avec BitNet, 100% hors ligne sur votre matÃ©riel â€” aucune donnÃ©e ne quitte votre appareil.\n\nQue souhaitez-vous explorer aujourd'hui ?",
        "Bonjour ! Je suis l'assistant ARIA sur votre appareil. Tout fonctionne localement, **sans dÃ©pendance au cloud**. Posez-moi des questions sur l'IA dÃ©centralisÃ©e, les modÃ¨les BitNet, ou discutons librement !",
      ],
      es: [
        "Â¡Hola! Soy tu asistente ARIA local, ejecutÃ¡ndome completamente en tu mÃ¡quina con inferencia BitNet. Â¿En quÃ© puedo ayudarte hoy?\n\nPuedo asistirte con:\n- **Entender el Protocolo ARIA** e IA descentralizada\n- **Rendimiento de modelos** y optimizaciÃ³n\n- **Preguntas tÃ©cnicas** sobre LLMs de 1-bit\n- **ConversaciÃ³n general** y lluvia de ideas",
        "Â¡Hola! Bienvenido al asistente de IA local de ARIA. Funciono con BitNet, 100% sin conexiÃ³n en tu hardware â€” ningÃºn dato sale de tu dispositivo.\n\nÂ¿QuÃ© te gustarÃ­a explorar hoy?",
      ],
      de: [
        "Hallo! Ich bin dein lokaler ARIA-Assistent und laufe vollstÃ¤ndig auf deinem Rechner mit BitNet-Inferenz. Wie kann ich dir heute helfen?\n\nIch kann dir helfen mit:\n- **ARIA-Protokoll verstehen** und dezentralisierte KI\n- **Modell-Performance** und Optimierung\n- **Technische Fragen** zu 1-bit LLMs\n- **Allgemeine GesprÃ¤che** und Brainstorming",
        "Hey! Willkommen beim lokalen KI-Assistenten von ARIA. Ich laufe mit BitNet, 100% offline auf deiner Hardware â€” keine Daten verlassen dein GerÃ¤t.\n\nWas mÃ¶chtest du heute erkunden?",
      ],
      pt: [
        "OlÃ¡! Sou seu assistente ARIA local, rodando inteiramente na sua mÃ¡quina com inferÃªncia BitNet. Como posso ajudÃ¡-lo hoje?\n\nPosso ajudar com:\n- **Entender o Protocolo ARIA** e IA descentralizada\n- **Performance de modelos** e otimizaÃ§Ã£o\n- **Perguntas tÃ©cnicas** sobre LLMs de 1-bit\n- **Conversa geral** e brainstorming",
        "Oi! Bem-vindo ao assistente de IA local do ARIA. Funciono com BitNet, 100% offline no seu hardware â€” nenhum dado sai do seu dispositivo.\n\nO que vocÃª gostaria de explorar hoje?",
      ],
      it: [
        "Ciao! Sono il tuo assistente ARIA locale, funziono interamente sulla tua macchina con inferenza BitNet. Come posso aiutarti oggi?\n\nPosso assisterti con:\n- **Capire il Protocollo ARIA** e IA decentralizzata\n- **Performance dei modelli** e ottimizzazione\n- **Domande tecniche** sui LLM a 1-bit\n- **Conversazione generale** e brainstorming",
        "Ciao! Benvenuto nell'assistente IA locale di ARIA. Funziono con BitNet, 100% offline sul tuo hardware â€” nessun dato lascia il tuo dispositivo.\n\nCosa vorresti esplorare oggi?",
      ],
      ja: [
        "ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯ARIAã®ãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚BitNetæ¨è«–ã§ã‚ãªãŸã®ãƒã‚·ãƒ³ä¸Šã§å®Œå…¨ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚ä»Šæ—¥ã¯ã©ã®ã‚ˆã†ã«ãŠæ‰‹ä¼ã„ã§ãã¾ã™ã‹ï¼Ÿ\n\nãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ï¼š\n- **ARIAãƒ—ãƒ­ãƒˆã‚³ãƒ«**ã¨åˆ†æ•£å‹AIã®ç†è§£\n- **ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯\n- **1-bit LLM**ã«é–¢ã™ã‚‹æŠ€è¡“çš„ãªè³ªå•\n- **ä¸€èˆ¬çš„ãªä¼šè©±**ã¨ãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°",
        "ã“ã‚“ã«ã¡ã¯ï¼ARIAã®ãƒ­ãƒ¼ã‚«ãƒ«AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¸ã‚ˆã†ã“ãã€‚BitNetã§å‹•ä½œã—ã€ã‚ãªãŸã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ä¸Šã§100%ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§å®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ä¸€åˆ‡å¤–éƒ¨ã«é€ä¿¡ã•ã‚Œã¾ã›ã‚“ã€‚\n\nä»Šæ—¥ã¯ä½•ã‚’æ¢æ±‚ã—ã¾ã™ã‹ï¼Ÿ",
      ],
      ko: [
        "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” BitNet ì¶”ë¡ ìœ¼ë¡œ ê·€í•˜ì˜ ì»´í“¨í„°ì—ì„œ ì™„ì „íˆ ì‹¤í–‰ë˜ëŠ” ARIA ë¡œì»¬ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n\në„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆëŠ” ë¶„ì•¼:\n- **ARIA í”„ë¡œí† ì½œ** ë° ë¶„ì‚°í˜• AI ì´í•´\n- **ëª¨ë¸ ì„±ëŠ¥** ë²¤ì¹˜ë§ˆí¬ ë° ìµœì í™”\n- **1-bit LLM**ì— ëŒ€í•œ ê¸°ìˆ ì  ì§ˆë¬¸\n- **ì¼ë°˜ ëŒ€í™”** ë° ë¸Œë ˆì¸ìŠ¤í† ë°",
        "ì•ˆë…•í•˜ì„¸ìš”! ARIAì˜ ë¡œì»¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. BitNetìœ¼ë¡œ êµ¬ë™ë˜ë©° ê·€í•˜ì˜ í•˜ë“œì›¨ì–´ì—ì„œ 100% ì˜¤í”„ë¼ì¸ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤. ë°ì´í„°ëŠ” ê¸°ê¸°ë¥¼ ë– ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\nì˜¤ëŠ˜ ë¬´ì—‡ì„ íƒìƒ‰í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
      ],
      zh: [
        "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ARIAæœ¬åœ°åŠ©æ‰‹ï¼Œé€šè¿‡BitNetæ¨ç†å®Œå…¨åœ¨ä½ çš„è®¾å¤‡ä¸Šè¿è¡Œã€‚ä»Šå¤©æˆ‘èƒ½å¸®ä½ ä»€ä¹ˆï¼Ÿ\n\næˆ‘å¯ä»¥å¸®åŠ©ä½ ï¼š\n- **äº†è§£ARIAåè®®**å’Œå»ä¸­å¿ƒåŒ–AI\n- **æ¨¡å‹æ€§èƒ½**åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–\n- **æŠ€æœ¯é—®é¢˜**å…³äº1-bit LLM\n- **æ—¥å¸¸å¯¹è¯**å’Œå¤´è„‘é£æš´",
        "ä½ å¥½ï¼æ¬¢è¿ä½¿ç”¨ARIAçš„æœ¬åœ°AIåŠ©æ‰‹ã€‚æˆ‘ä½¿ç”¨BitNetï¼Œ100%ç¦»çº¿è¿è¡Œåœ¨ä½ çš„ç¡¬ä»¶ä¸Šâ€”â€”æ²¡æœ‰æ•°æ®ä¼šç¦»å¼€ä½ çš„è®¾å¤‡ã€‚\n\nä»Šå¤©ä½ æƒ³æ¢ç´¢ä»€ä¹ˆï¼Ÿ",
      ],
      ru: [
        "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¯ Ğ²Ğ°Ñˆ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº ARIA, Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ½Ğ° Ğ²Ğ°ÑˆĞµĞ¼ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğµ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ BitNet. Ğ§ĞµĞ¼ Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ?\n\nĞ¯ Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ Ñ:\n- **ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğ° ARIA** Ğ¸ Ğ´ĞµÑ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ˜Ğ˜\n- **ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹** Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸ĞµĞ¹\n- **Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ°Ğ¼Ğ¸** Ğ¾ 1-bit LLM\n- **ĞĞ±Ñ‰ĞµĞ½Ğ¸ĞµĞ¼** Ğ¸ Ğ¼Ğ¾Ğ·Ğ³Ğ¾Ğ²Ñ‹Ğ¼ ÑˆÑ‚ÑƒÑ€Ğ¼Ğ¾Ğ¼",
        "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ”Ğ¾Ğ±Ñ€Ğ¾ Ğ¿Ğ¾Ğ¶Ğ°Ğ»Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ˜Ğ˜-Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº ARIA. Ğ¯ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ Ğ½Ğ° BitNet, 100% Ğ¾Ñ„Ğ»Ğ°Ğ¹Ğ½ Ğ½Ğ° Ğ²Ğ°ÑˆĞµĞ¼ Ğ¾Ğ±Ğ¾Ñ€ÑƒĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ â€” Ğ½Ğ¸ĞºĞ°ĞºĞ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğµ Ğ¿Ğ¾ĞºĞ¸Ğ´Ğ°ÑÑ‚ Ğ²Ğ°ÑˆĞµ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ¾.\n\nĞ§Ñ‚Ğ¾ Ğ±Ñ‹ Ğ²Ñ‹ Ñ…Ğ¾Ñ‚ĞµĞ»Ğ¸ ÑƒĞ·Ğ½Ğ°Ñ‚ÑŒ ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ?",
      ],
      ar: [
        "Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯ ARIA Ø§Ù„Ù…Ø­Ù„ÙŠ Ø§Ù„Ø®Ø§Øµ Ø¨ÙƒØŒ Ø£Ø¹Ù…Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³ØªØ¯Ù„Ø§Ù„ BitNet. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ\n\nÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ:\n- **ÙÙ‡Ù… Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ ARIA** ÙˆØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù„Ø§Ù…Ø±ÙƒØ²ÙŠ\n- **Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬** ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†\n- **Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ©** Ø­ÙˆÙ„ Ù†Ù…Ø§Ø°Ø¬ 1-bit LLM\n- **Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¹Ø§Ù…Ø©** ÙˆØ§Ù„Ø¹ØµÙ Ø§Ù„Ø°Ù‡Ù†ÙŠ",
      ],
      hi: [
        "à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¤¾ à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ ARIA à¤¸à¤¹à¤¾à¤¯à¤• à¤¹à¥‚à¤, BitNet à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤•à¥‡ à¤¸à¤¾à¤¥ à¤ªà¥‚à¤°à¥€ à¤¤à¤°à¤¹ à¤¸à¥‡ à¤†à¤ªà¤•à¥€ à¤®à¤¶à¥€à¤¨ à¤ªà¤° à¤šà¤² à¤°à¤¹à¤¾ à¤¹à¥‚à¤à¥¤ à¤†à¤œ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ à¤•à¥ˆà¤¸à¥‡ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤?\n\nà¤®à¥ˆà¤‚ à¤‡à¤¨à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤:\n- **ARIA à¤ªà¥à¤°à¥‹à¤Ÿà¥‹à¤•à¥‰à¤²** à¤”à¤° à¤µà¤¿à¤•à¥‡à¤‚à¤¦à¥à¤°à¥€à¤•à¥ƒà¤¤ AI à¤•à¥‹ à¤¸à¤®à¤à¤¨à¤¾\n- **à¤®à¥‰à¤¡à¤² à¤ªà¥à¤°à¤¦à¤°à¥à¤¶à¤¨** à¤¬à¥‡à¤‚à¤šà¤®à¤¾à¤°à¥à¤• à¤”à¤° à¤…à¤¨à¥à¤•à¥‚à¤²à¤¨\n- **à¤¤à¤•à¤¨à¥€à¤•à¥€ à¤ªà¥à¤°à¤¶à¥à¤¨** 1-bit LLM à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚\n- **à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤¬à¤¾à¤¤à¤šà¥€à¤¤** à¤”à¤° à¤µà¤¿à¤šà¤¾à¤°-à¤®à¤‚à¤¥à¤¨",
      ],
    },
  },
  {
    // ARIA / Protocol / Decentralized
    pattern:
      /\b(aria|protocol|decentralized|dÃ©centralisÃ©|descentralizado|dezentral|decentralizzato|åˆ†æ•£å‹|íƒˆì¤‘ì•™|å»ä¸­å¿ƒåŒ–|Ğ´ĞµÑ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·|Ù„Ø§Ù…Ø±ÙƒØ²ÙŠ|à¤µà¤¿à¤•à¥‡à¤‚à¤¦à¥à¤°à¥€à¤•à¥ƒà¤¤)\b/iu,
    responses: {
      en: [
        "**ARIA Protocol** is a decentralized AI inference network that enables anyone to run and share AI models locally.\n\n### Core Principles\n- **Decentralization**: No single point of failure or control\n- **Privacy**: All inference happens on-device by default\n- **Efficiency**: Built on 1-bit LLMs (BitNet) for minimal resource usage\n- **Accessibility**: Runs on consumer hardware â€” no GPU required\n\n### Architecture\n```\nUser Request â†’ Local Node â†’ BitNet Inference â†’ Response\n                  â†•\n           ARIA P2P Network\n                  â†•\n            Other Nodes (optional)\n```\n\nThe protocol coordinates distributed inference across a peer-to-peer network while keeping data sovereignty with each node operator.",
        "ARIA Protocol is pioneering **decentralized AI** by leveraging 1-bit quantized models (BitNet) that run efficiently on CPUs.\n\n### Key Features\n- **Local-first**: Models run on your hardware\n- **P2P Network**: Nodes collaborate for larger workloads\n- **Energy efficient**: Up to 71x less energy than FP16 models\n- **Open source**: Fully transparent and community-driven\n\nThe goal is to democratize AI by removing the dependency on centralized cloud providers and expensive GPU infrastructure.",
      ],
      fr: [
        "**Le Protocole ARIA** est un rÃ©seau d'infÃ©rence IA dÃ©centralisÃ© qui permet Ã  quiconque d'exÃ©cuter et de partager des modÃ¨les IA localement.\n\n### Principes fondamentaux\n- **DÃ©centralisation** : Aucun point unique de dÃ©faillance ou de contrÃ´le\n- **ConfidentialitÃ©** : Toute l'infÃ©rence se fait sur l'appareil par dÃ©faut\n- **EfficacitÃ©** : BasÃ© sur les LLM 1-bit (BitNet) pour une utilisation minimale des ressources\n- **AccessibilitÃ©** : Fonctionne sur du matÃ©riel grand public â€” pas de GPU requis\n\n### Architecture\n```\nRequÃªte â†’ NÅ“ud Local â†’ InfÃ©rence BitNet â†’ RÃ©ponse\n              â†•\n       RÃ©seau P2P ARIA\n              â†•\n       Autres NÅ“uds (optionnel)\n```\n\nLe protocole coordonne l'infÃ©rence distribuÃ©e Ã  travers un rÃ©seau pair-Ã -pair tout en gardant la souverainetÃ© des donnÃ©es avec chaque opÃ©rateur de nÅ“ud.",
      ],
      es: [
        "**El Protocolo ARIA** es una red de inferencia de IA descentralizada que permite a cualquiera ejecutar y compartir modelos de IA localmente.\n\n### Principios fundamentales\n- **DescentralizaciÃ³n**: Sin punto Ãºnico de fallo o control\n- **Privacidad**: Toda la inferencia ocurre en el dispositivo por defecto\n- **Eficiencia**: Construido sobre LLMs de 1-bit (BitNet) para uso mÃ­nimo de recursos\n- **Accesibilidad**: Funciona en hardware de consumo â€” no requiere GPU\n\nEl objetivo es democratizar la IA eliminando la dependencia de proveedores cloud centralizados e infraestructura GPU costosa.",
      ],
      de: [
        "**ARIA-Protokoll** ist ein dezentralisiertes KI-Inferenz-Netzwerk, das es jedem ermÃ¶glicht, KI-Modelle lokal auszufÃ¼hren und zu teilen.\n\n### Kernprinzipien\n- **Dezentralisierung**: Kein einzelner Ausfallpunkt oder Kontrollpunkt\n- **Datenschutz**: Alle Inferenz findet standardmÃ¤ÃŸig auf dem GerÃ¤t statt\n- **Effizienz**: Basiert auf 1-bit LLMs (BitNet) fÃ¼r minimalen Ressourcenverbrauch\n- **ZugÃ¤nglichkeit**: LÃ¤uft auf Consumer-Hardware â€” keine GPU erforderlich\n\nDas Ziel ist die Demokratisierung von KI durch Beseitigung der AbhÃ¤ngigkeit von zentralisierten Cloud-Anbietern.",
      ],
      pt: [
        "**O Protocolo ARIA** Ã© uma rede de inferÃªncia de IA descentralizada que permite a qualquer pessoa executar e compartilhar modelos de IA localmente.\n\n### PrincÃ­pios fundamentais\n- **DescentralizaÃ§Ã£o**: Sem ponto Ãºnico de falha ou controle\n- **Privacidade**: Toda inferÃªncia acontece no dispositivo por padrÃ£o\n- **EficiÃªncia**: ConstruÃ­do em LLMs de 1-bit (BitNet) para uso mÃ­nimo de recursos\n- **Acessibilidade**: Funciona em hardware comum â€” nÃ£o requer GPU\n\nO objetivo Ã© democratizar a IA removendo a dependÃªncia de provedores de nuvem centralizados.",
      ],
      it: [
        "**Il Protocollo ARIA** Ã¨ una rete di inferenza IA decentralizzata che permette a chiunque di eseguire e condividere modelli IA localmente.\n\n### Principi fondamentali\n- **Decentralizzazione**: Nessun singolo punto di fallimento o controllo\n- **Privacy**: Tutta l'inferenza avviene sul dispositivo per impostazione predefinita\n- **Efficienza**: Costruito su LLM a 1-bit (BitNet) per un utilizzo minimo delle risorse\n- **AccessibilitÃ **: Funziona su hardware consumer â€” nessuna GPU richiesta\n\nL'obiettivo Ã¨ democratizzare l'IA eliminando la dipendenza dai provider cloud centralizzati.",
      ],
      ja: [
        "**ARIAãƒ—ãƒ­ãƒˆã‚³ãƒ«**ã¯ã€èª°ã§ã‚‚ãƒ­ãƒ¼ã‚«ãƒ«ã§AIãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œãƒ»å…±æœ‰ã§ãã‚‹åˆ†æ•£å‹AIæ¨è«–ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚\n\n### åŸºæœ¬åŸå‰‡\n- **åˆ†æ•£åŒ–**: å˜ä¸€éšœå®³ç‚¹ã‚„åˆ¶å¾¡ç‚¹ãªã—\n- **ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼**: ã™ã¹ã¦ã®æ¨è«–ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ãƒ‡ãƒã‚¤ã‚¹ä¸Šã§å®Ÿè¡Œ\n- **åŠ¹ç‡æ€§**: æœ€å°é™ã®ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨ã®ãŸã‚ã®1-bit LLMï¼ˆBitNetï¼‰åŸºç›¤\n- **ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£**: ä¸€èˆ¬æ¶ˆè²»è€…å‘ã‘ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§å‹•ä½œ â€” GPUã¯ä¸è¦\n\nç›®æ¨™ã¯ã€ä¸­å¤®é›†æ¨©çš„ãªã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã¸ã®ä¾å­˜ã‚’æ’é™¤ã—ã¦AIã‚’æ°‘ä¸»åŒ–ã™ã‚‹ã“ã¨ã§ã™ã€‚",
      ],
      ko: [
        "**ARIA í”„ë¡œí† ì½œ**ì€ ëˆ„êµ¬ë‚˜ AI ëª¨ë¸ì„ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ê³  ê³µìœ í•  ìˆ˜ ìˆëŠ” ë¶„ì‚°í˜• AI ì¶”ë¡  ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤.\n\n### í•µì‹¬ ì›ì¹™\n- **íƒˆì¤‘ì•™í™”**: ë‹¨ì¼ ì¥ì• ì ì´ë‚˜ ì œì–´ì  ì—†ìŒ\n- **í”„ë¼ì´ë²„ì‹œ**: ëª¨ë“  ì¶”ë¡ ì€ ê¸°ë³¸ì ìœ¼ë¡œ ê¸°ê¸°ì—ì„œ ìˆ˜í–‰\n- **íš¨ìœ¨ì„±**: ìµœì†Œí•œì˜ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ì„ ìœ„í•œ 1-bit LLM (BitNet) ê¸°ë°˜\n- **ì ‘ê·¼ì„±**: ì¼ë°˜ ì†Œë¹„ì í•˜ë“œì›¨ì–´ì—ì„œ ì‹¤í–‰ â€” GPU ë¶ˆí•„ìš”\n\nëª©í‘œëŠ” ì¤‘ì•™ ì§‘ì¤‘ì‹ í´ë¼ìš°ë“œ ì œê³µì—…ì²´ì— ëŒ€í•œ ì˜ì¡´ì„±ì„ ì œê±°í•˜ì—¬ AIë¥¼ ë¯¼ì£¼í™”í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.",
      ],
      zh: [
        "**ARIAåè®®**æ˜¯ä¸€ä¸ªå»ä¸­å¿ƒåŒ–çš„AIæ¨ç†ç½‘ç»œï¼Œä½¿ä»»ä½•äººéƒ½å¯ä»¥åœ¨æœ¬åœ°è¿è¡Œå’Œå…±äº«AIæ¨¡å‹ã€‚\n\n### æ ¸å¿ƒåŸåˆ™\n- **å»ä¸­å¿ƒåŒ–**: æ²¡æœ‰å•ç‚¹æ•…éšœæˆ–æ§åˆ¶\n- **éšç§**: æ‰€æœ‰æ¨ç†é»˜è®¤åœ¨è®¾å¤‡ä¸Šè¿›è¡Œ\n- **æ•ˆç‡**: åŸºäº1-bit LLMï¼ˆBitNetï¼‰å®ç°æœ€å°èµ„æºä½¿ç”¨\n- **å¯è®¿é—®æ€§**: åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè¿è¡Œ â€” ä¸éœ€è¦GPU\n\nç›®æ ‡æ˜¯é€šè¿‡æ¶ˆé™¤å¯¹ä¸­å¿ƒåŒ–äº‘æä¾›å•†çš„ä¾èµ–æ¥å®ç°AIæ°‘ä¸»åŒ–ã€‚",
      ],
      ru: [
        "**ĞŸÑ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» ARIA** â€” ÑÑ‚Ğ¾ Ğ´ĞµÑ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ°Ñ ÑĞµÑ‚ÑŒ AI-Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ»ÑĞ±Ğ¾Ğ¼Ñƒ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ Ğ¸ Ğ´ĞµĞ»Ğ¸Ñ‚ÑŒÑÑ AI-Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼Ğ¸ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾.\n\n### ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ñ‹\n- **Ğ”ĞµÑ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ**: ĞĞµÑ‚ ĞµĞ´Ğ¸Ğ½Ğ¾Ğ¹ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ¾Ñ‚ĞºĞ°Ğ·Ğ° Ğ¸Ğ»Ğ¸ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ñ\n- **ĞšĞ¾Ğ½Ñ„Ğ¸Ğ´ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ**: Ğ’ĞµÑÑŒ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ½Ğ° ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğµ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ\n- **Ğ­Ñ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ**: ĞŸĞ¾ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ½Ğ° 1-bit LLM (BitNet) Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ€ĞµÑÑƒÑ€ÑĞ¾Ğ²\n- **Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ÑÑ‚ÑŒ**: Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ¸Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ¼ Ğ¾Ğ±Ğ¾Ñ€ÑƒĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ â€” GPU Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ\n\nĞ¦ĞµĞ»ÑŒ â€” Ğ´ĞµĞ¼Ğ¾ĞºÑ€Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ˜Ğ˜, ÑƒÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ğ² Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ¾Ñ‚ Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¾Ğ±Ğ»Ğ°Ñ‡Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ².",
      ],
      ar: [
        "**Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ ARIA** Ù‡Ùˆ Ø´Ø¨ÙƒØ© Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø§Ù…Ø±ÙƒØ²ÙŠØ© ØªØªÙŠØ­ Ù„Ø£ÙŠ Ø´Ø®Øµ ØªØ´ØºÙŠÙ„ ÙˆÙ…Ø´Ø§Ø±ÙƒØ© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø­Ù„ÙŠÙ‹Ø§.\n\n### Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n- **Ø§Ù„Ù„Ø§Ù…Ø±ÙƒØ²ÙŠØ©**: Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†Ù‚Ø·Ø© ÙØ´Ù„ Ø£Ùˆ ØªØ­ÙƒÙ… ÙˆØ§Ø­Ø¯Ø©\n- **Ø§Ù„Ø®ØµÙˆØµÙŠØ©**: ÙŠØªÙ… Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§ÙØªØ±Ø§Ø¶ÙŠÙ‹Ø§\n- **Ø§Ù„ÙƒÙØ§Ø¡Ø©**: Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ 1-bit LLM (BitNet) Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ§Ø±Ø¯ Ø£Ù‚Ù„\n- **Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„**: ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ù„ÙƒÙŠÙ† â€” Ù„Ø§ ÙŠØªØ·Ù„Ø¨ GPU",
      ],
      hi: [
        "**ARIA à¤ªà¥à¤°à¥‹à¤Ÿà¥‹à¤•à¥‰à¤²** à¤à¤• à¤µà¤¿à¤•à¥‡à¤‚à¤¦à¥à¤°à¥€à¤•à¥ƒà¤¤ AI à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤¨à¥‡à¤Ÿà¤µà¤°à¥à¤• à¤¹à¥ˆ à¤œà¥‹ à¤•à¤¿à¤¸à¥€ à¤•à¥‹ à¤­à¥€ AI à¤®à¥‰à¤¡à¤² à¤•à¥‹ à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ à¤°à¥‚à¤ª à¤¸à¥‡ à¤šà¤²à¤¾à¤¨à¥‡ à¤”à¤° à¤¸à¤¾à¤à¤¾ à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ à¤¸à¤•à¥à¤·à¤® à¤¬à¤¨à¤¾à¤¤à¤¾ à¤¹à¥ˆà¥¤\n\n### à¤®à¥‚à¤² à¤¸à¤¿à¤¦à¥à¤§à¤¾à¤‚à¤¤\n- **à¤µà¤¿à¤•à¥‡à¤‚à¤¦à¥à¤°à¥€à¤•à¤°à¤£**: à¤•à¥‹à¤ˆ à¤à¤•à¤² à¤µà¤¿à¤«à¤²à¤¤à¤¾ à¤¯à¤¾ à¤¨à¤¿à¤¯à¤‚à¤¤à¥à¤°à¤£ à¤¬à¤¿à¤‚à¤¦à¥ à¤¨à¤¹à¥€à¤‚\n- **à¤—à¥‹à¤ªà¤¨à¥€à¤¯à¤¤à¤¾**: à¤¸à¤­à¥€ à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤¡à¤¿à¤«à¤¼à¥‰à¤²à¥à¤Ÿ à¤°à¥‚à¤ª à¤¸à¥‡ à¤¡à¤¿à¤µà¤¾à¤‡à¤¸ à¤ªà¤° à¤¹à¥‹à¤¤à¥‡ à¤¹à¥ˆà¤‚\n- **à¤¦à¤•à¥à¤·à¤¤à¤¾**: à¤¨à¥à¤¯à¥‚à¤¨à¤¤à¤® à¤¸à¤‚à¤¸à¤¾à¤§à¤¨ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¥‡ à¤²à¤¿à¤ 1-bit LLM (BitNet) à¤ªà¤° à¤¨à¤¿à¤°à¥à¤®à¤¿à¤¤\n- **à¤ªà¤¹à¥à¤‚à¤š**: à¤‰à¤ªà¤­à¥‹à¤•à¥à¤¤à¤¾ à¤¹à¤¾à¤°à¥à¤¡à¤µà¥‡à¤¯à¤° à¤ªà¤° à¤šà¤²à¤¤à¤¾ à¤¹à¥ˆ â€” GPU à¤•à¥€ à¤†à¤µà¤¶à¥à¤¯à¤•à¤¤à¤¾ à¤¨à¤¹à¥€à¤‚\n\nà¤²à¤•à¥à¤·à¥à¤¯ à¤•à¥‡à¤‚à¤¦à¥à¤°à¥€à¤•à¥ƒà¤¤ à¤•à¥à¤²à¤¾à¤‰à¤¡ à¤ªà¥à¤°à¤¦à¤¾à¤¤à¤¾à¤“à¤‚ à¤ªà¤° à¤¨à¤¿à¤°à¥à¤­à¤°à¤¤à¤¾ à¤•à¥‹ à¤¹à¤Ÿà¤¾à¤•à¤° AI à¤•à¥‹ à¤²à¥‹à¤•à¤¤à¤¾à¤‚à¤¤à¥à¤°à¤¿à¤• à¤¬à¤¨à¤¾à¤¨à¤¾ à¤¹à¥ˆà¥¤",
      ],
    },
  },
  {
    // BitNet / 1-bit / quantization / energy
    pattern:
      /\b(bitnet|1-bit|quantiz|energy|Ã©nergie|energÃ­a|energie|energia|ã‚¨ãƒãƒ«ã‚®ãƒ¼|ì—ë„ˆì§€|èƒ½æº|ÑĞ½ĞµÑ€Ğ³Ğ¸Ñ|Ø·Ø§Ù‚Ø©|à¤Šà¤°à¥à¤œà¤¾)\b/iu,
    responses: {
      en: [
        "**BitNet** is a revolutionary approach to large language models using **1-bit quantization**.\n\n### How It Works\nTraditional LLMs use 16-bit or 32-bit floating point weights. BitNet constrains weights to just **{-1, 0, 1}**, which means:\n\n```\nTraditional: multiply + accumulate (expensive)\nBitNet:      add/subtract only (cheap & fast)\n```\n\n### Benefits\n- **Memory**: 8-10x reduction in model size\n- **Speed**: Matrix multiplications become simple additions\n- **Energy**: 71.4x less energy consumption\n- **Hardware**: No GPU required â€” runs on any CPU\n\n### Available Models in ARIA\n1. **BitNet-b1.58-large** (0.7B) â€” Fast, lightweight\n2. **BitNet-b1.58-2B-4T** (2.4B) â€” Best balance â­\n3. **Llama3-8B-1.58** (8B) â€” Most capable",
        "Energy efficiency is a **core pillar** of ARIA Protocol.\n\n### The Problem\nTraditional AI inference is energy-intensive:\n- A single ChatGPT query uses ~10x more energy than a Google search\n- Data centers account for 1-2% of global electricity\n\n### ARIA's Solution\nBy using **BitNet 1-bit models**:\n- **71.4x** less energy per token vs FP16\n- **CPU-only** inference â€” no power-hungry GPUs\n- **Distributed** workload across efficient nodes\n\n| Metric | Traditional | ARIA (BitNet) |\n|--------|------------|---------------|\n| Energy/token | 170 mJ | 2.4 mJ |\n| Hardware | A100 GPU | Laptop CPU |\n\nDecentralized AI doesn't just protect privacy â€” it's better for the planet.",
      ],
      fr: [
        "**BitNet** est une approche rÃ©volutionnaire des grands modÃ¨les de langage utilisant la **quantification 1-bit**.\n\n### Comment Ã§a fonctionne\nLes LLM traditionnels utilisent des poids en virgule flottante 16-bit ou 32-bit. BitNet contraint les poids Ã  seulement **{-1, 0, 1}**, ce qui signifie :\n\n```\nTraditionnel: multiplication + accumulation (coÃ»teux)\nBitNet:       addition/soustraction uniquement (rapide)\n```\n\n### Avantages\n- **MÃ©moire**: RÃ©duction de 8-10x de la taille du modÃ¨le\n- **Vitesse**: Les multiplications matricielles deviennent de simples additions\n- **Ã‰nergie**: 71.4x moins de consommation d'Ã©nergie\n- **MatÃ©riel**: Pas de GPU requis â€” fonctionne sur n'importe quel CPU\n\n### ModÃ¨les disponibles dans ARIA\n1. **BitNet-b1.58-large** (0.7B) â€” Rapide, lÃ©ger\n2. **BitNet-b1.58-2B-4T** (2.4B) â€” Meilleur Ã©quilibre â­\n3. **Llama3-8B-1.58** (8B) â€” Le plus capable",
      ],
      es: [
        "**BitNet** es un enfoque revolucionario para modelos de lenguaje grandes usando **cuantizaciÃ³n de 1-bit**.\n\n### CÃ³mo funciona\nLos LLMs tradicionales usan pesos de punto flotante de 16-bit o 32-bit. BitNet restringe los pesos a solo **{-1, 0, 1}**:\n\n```\nTradicional: multiplicaciÃ³n + acumulaciÃ³n (costoso)\nBitNet:      solo suma/resta (rÃ¡pido)\n```\n\n### Beneficios\n- **Memoria**: ReducciÃ³n de 8-10x en tamaÃ±o del modelo\n- **Velocidad**: Las multiplicaciones matriciales se convierten en sumas simples\n- **EnergÃ­a**: 71.4x menos consumo de energÃ­a\n- **Hardware**: No requiere GPU â€” funciona en cualquier CPU",
      ],
      de: [
        "**BitNet** ist ein revolutionÃ¤rer Ansatz fÃ¼r groÃŸe Sprachmodelle mit **1-bit-Quantisierung**.\n\n### Wie es funktioniert\nTraditionelle LLMs verwenden 16-bit oder 32-bit FlieÃŸkomma-Gewichte. BitNet beschrÃ¤nkt Gewichte auf nur **{-1, 0, 1}**:\n\n```\nTraditionell: Multiplikation + Akkumulation (teuer)\nBitNet:       nur Addition/Subtraktion (schnell)\n```\n\n### Vorteile\n- **Speicher**: 8-10x Reduzierung der ModellgrÃ¶ÃŸe\n- **Geschwindigkeit**: Matrixmultiplikationen werden zu einfachen Additionen\n- **Energie**: 71.4x weniger Energieverbrauch\n- **Hardware**: Keine GPU erforderlich â€” lÃ¤uft auf jeder CPU",
      ],
      pt: [
        "**BitNet** Ã© uma abordagem revolucionÃ¡ria para modelos de linguagem grandes usando **quantizaÃ§Ã£o de 1-bit**.\n\n### Como funciona\nLLMs tradicionais usam pesos de ponto flutuante de 16-bit ou 32-bit. BitNet restringe os pesos a apenas **{-1, 0, 1}**:\n\n### BenefÃ­cios\n- **MemÃ³ria**: ReduÃ§Ã£o de 8-10x no tamanho do modelo\n- **Velocidade**: MultiplicaÃ§Ãµes de matriz se tornam adiÃ§Ãµes simples\n- **Energia**: 71.4x menos consumo de energia\n- **Hardware**: NÃ£o requer GPU â€” funciona em qualquer CPU",
      ],
      it: [
        "**BitNet** Ã¨ un approccio rivoluzionario ai grandi modelli linguistici usando **quantizzazione a 1-bit**.\n\n### Come funziona\nI LLM tradizionali usano pesi in virgola mobile a 16-bit o 32-bit. BitNet limita i pesi a solo **{-1, 0, 1}**:\n\n### Benefici\n- **Memoria**: Riduzione di 8-10x della dimensione del modello\n- **VelocitÃ **: Le moltiplicazioni di matrici diventano semplici addizioni\n- **Energia**: 71.4x meno consumo energetico\n- **Hardware**: Nessuna GPU richiesta â€” funziona su qualsiasi CPU",
      ],
      ja: [
        "**BitNet**ã¯ã€**1-bité‡å­åŒ–**ã‚’ä½¿ç”¨ã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¸ã®é©æ–°çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã™ã€‚\n\n### ä»•çµ„ã¿\nå¾“æ¥ã®LLMã¯16-bitã¾ãŸã¯32-bitã®æµ®å‹•å°æ•°ç‚¹é‡ã¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚BitNetã¯é‡ã¿ã‚’**{-1, 0, 1}**ã®ã¿ã«åˆ¶é™ã—ã¾ã™ï¼š\n\n### ãƒ¡ãƒªãƒƒãƒˆ\n- **ãƒ¡ãƒ¢ãƒª**: ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒ8-10å€å‰Šæ¸›\n- **é€Ÿåº¦**: è¡Œåˆ—ä¹—ç®—ãŒå˜ç´”ãªåŠ ç®—ã«\n- **ã‚¨ãƒãƒ«ã‚®ãƒ¼**: 71.4å€å°‘ãªã„æ¶ˆè²»é›»åŠ›\n- **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢**: GPUã¯ä¸è¦ â€” ã©ã®CPUã§ã‚‚å‹•ä½œ",
      ],
      ko: [
        "**BitNet**ì€ **1-bit ì–‘ìí™”**ë¥¼ ì‚¬ìš©í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•œ í˜ì‹ ì ì¸ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤.\n\n### ì‘ë™ ë°©ì‹\nì „í†µì ì¸ LLMì€ 16-bit ë˜ëŠ” 32-bit ë¶€ë™ ì†Œìˆ˜ì  ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. BitNetì€ ê°€ì¤‘ì¹˜ë¥¼ **{-1, 0, 1}**ë¡œë§Œ ì œí•œí•©ë‹ˆë‹¤:\n\n### ì´ì \n- **ë©”ëª¨ë¦¬**: ëª¨ë¸ í¬ê¸° 8-10ë°° ê°ì†Œ\n- **ì†ë„**: í–‰ë ¬ ê³±ì…ˆì´ ë‹¨ìˆœ ë§ì…ˆìœ¼ë¡œ ë³€í™˜\n- **ì—ë„ˆì§€**: 71.4ë°° ì ì€ ì—ë„ˆì§€ ì†Œë¹„\n- **í•˜ë“œì›¨ì–´**: GPU ë¶ˆí•„ìš” â€” ëª¨ë“  CPUì—ì„œ ì‹¤í–‰",
      ],
      zh: [
        "**BitNet**æ˜¯ä½¿ç”¨**1-bité‡åŒ–**çš„å¤§å‹è¯­è¨€æ¨¡å‹çš„é©å‘½æ€§æ–¹æ³•ã€‚\n\n### å·¥ä½œåŸç†\nä¼ ç»ŸLLMä½¿ç”¨16ä½æˆ–32ä½æµ®ç‚¹æƒé‡ã€‚BitNetå°†æƒé‡é™åˆ¶ä¸ºä»…**{-1, 0, 1}**ï¼š\n\n### ä¼˜åŠ¿\n- **å†…å­˜**: æ¨¡å‹å¤§å°å‡å°‘8-10å€\n- **é€Ÿåº¦**: çŸ©é˜µä¹˜æ³•å˜æˆç®€å•åŠ æ³•\n- **èƒ½æº**: èƒ½è€—é™ä½71.4å€\n- **ç¡¬ä»¶**: æ— éœ€GPU â€” åœ¨ä»»ä½•CPUä¸Šè¿è¡Œ",
      ],
      ru: [
        "**BitNet** â€” ÑÑ‚Ğ¾ Ñ€ĞµĞ²Ğ¾Ğ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ´Ñ…Ğ¾Ğ´ Ğº Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ **1-bit ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸**.\n\n### ĞšĞ°Ğº ÑÑ‚Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚\nĞ¢Ñ€Ğ°Ğ´Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğµ LLM Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ 16-bit Ğ¸Ğ»Ğ¸ 32-bit Ğ²ĞµÑĞ° Ñ Ğ¿Ğ»Ğ°Ğ²Ğ°ÑÑ‰ĞµĞ¹ Ñ‚Ğ¾Ñ‡ĞºĞ¾Ğ¹. BitNet Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ²ĞµÑĞ° Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ **{-1, 0, 1}**:\n\n### ĞŸÑ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ°\n- **ĞŸĞ°Ğ¼ÑÑ‚ÑŒ**: Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ² 8-10 Ñ€Ğ°Ğ·\n- **Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ**: ĞœĞ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑƒĞ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ÑÑ‚ÑÑ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğ¼Ğ¸ ÑĞ»Ğ¾Ğ¶ĞµĞ½Ğ¸ÑĞ¼Ğ¸\n- **Ğ­Ğ½ĞµÑ€Ğ³Ğ¸Ñ**: Ğ’ 71.4 Ñ€Ğ°Ğ·Ğ° Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ½ĞµÑ€Ğ³Ğ¸Ğ¸\n- **ĞĞ±Ğ¾Ñ€ÑƒĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ**: GPU Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ â€” Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° Ğ»ÑĞ±Ğ¾Ğ¼ CPU",
      ],
      ar: [
        "**BitNet** Ù‡Ùˆ Ù†Ù‡Ø¬ Ø«ÙˆØ±ÙŠ Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… **Ø§Ù„ØªÙƒÙ…ÙŠÙ… 1-bit**.\n\n### ÙƒÙŠÙ ÙŠØ¹Ù…Ù„\nØªØ³ØªØ®Ø¯Ù… Ù†Ù…Ø§Ø°Ø¬ LLM Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ© Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ø¹Ø§Ø¦Ù…Ø© 16-bit Ø£Ùˆ 32-bit. ÙŠÙ‚ÙŠØ¯ BitNet Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø¥Ù„Ù‰ **{-1, 0, 1}** ÙÙ‚Ø·:\n\n### Ø§Ù„ÙÙˆØ§Ø¦Ø¯\n- **Ø§Ù„Ø°Ø§ÙƒØ±Ø©**: ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ 8-10 Ù…Ø±Ø§Øª\n- **Ø§Ù„Ø³Ø±Ø¹Ø©**: ØªØµØ¨Ø­ Ø¹Ù…Ù„ÙŠØ§Øª Ø¶Ø±Ø¨ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª Ø¥Ø¶Ø§ÙØ§Øª Ø¨Ø³ÙŠØ·Ø©\n- **Ø§Ù„Ø·Ø§Ù‚Ø©**: Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø·Ø§Ù‚Ø© Ø£Ù‚Ù„ Ø¨Ù€ 71.4 Ù…Ø±Ø©\n- **Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©**: Ù„Ø§ ÙŠØªØ·Ù„Ø¨ GPU â€” ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø£ÙŠ CPU",
      ],
      hi: [
        "**BitNet** **1-bit à¤•à¥à¤µà¤¾à¤‚à¤Ÿà¤¾à¤‡à¤œà¥‡à¤¶à¤¨** à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¤¤à¥‡ à¤¹à¥à¤ à¤¬à¤¡à¤¼à¥‡ à¤­à¤¾à¤·à¤¾ à¤®à¥‰à¤¡à¤² à¤•à¥‡ à¤²à¤¿à¤ à¤à¤• à¤•à¥à¤°à¤¾à¤‚à¤¤à¤¿à¤•à¤¾à¤°à¥€ à¤¦à¥ƒà¤·à¥à¤Ÿà¤¿à¤•à¥‹à¤£ à¤¹à¥ˆà¥¤\n\n### à¤¯à¤¹ à¤•à¥ˆà¤¸à¥‡ à¤•à¤¾à¤® à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ\nà¤ªà¤¾à¤°à¤‚à¤ªà¤°à¤¿à¤• LLM 16-bit à¤¯à¤¾ 32-bit à¤«à¥à¤²à¥‹à¤Ÿà¤¿à¤‚à¤— à¤ªà¥‰à¤‡à¤‚à¤Ÿ à¤µà¥‡à¤Ÿ à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤ BitNet à¤µà¥‡à¤Ÿ à¤•à¥‹ à¤•à¥‡à¤µà¤² **{-1, 0, 1}** à¤¤à¤• à¤¸à¥€à¤®à¤¿à¤¤ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ:\n\n### à¤²à¤¾à¤­\n- **à¤®à¥‡à¤®à¥‹à¤°à¥€**: à¤®à¥‰à¤¡à¤² à¤†à¤•à¤¾à¤° à¤®à¥‡à¤‚ 8-10x à¤•à¥€ à¤•à¤®à¥€\n- **à¤—à¤¤à¤¿**: à¤®à¥ˆà¤Ÿà¥à¤°à¤¿à¤•à¥à¤¸ à¤—à¥à¤£à¤¨ à¤¸à¤°à¤² à¤œà¥‹à¤¡à¤¼ à¤¬à¤¨ à¤œà¤¾à¤¤à¥‡ à¤¹à¥ˆà¤‚\n- **à¤Šà¤°à¥à¤œà¤¾**: 71.4x à¤•à¤® à¤Šà¤°à¥à¤œà¤¾ à¤–à¤ªà¤¤\n- **à¤¹à¤¾à¤°à¥à¤¡à¤µà¥‡à¤¯à¤°**: GPU à¤•à¥€ à¤†à¤µà¤¶à¥à¤¯à¤•à¤¤à¤¾ à¤¨à¤¹à¥€à¤‚ â€” à¤•à¤¿à¤¸à¥€ à¤­à¥€ CPU à¤ªà¤° à¤šà¤²à¤¤à¤¾ à¤¹à¥ˆ",
      ],
    },
  },
  {
    // Benchmark / Performance
    pattern: /\b(benchmark|performance|speed|fast|token|rendimiento|leistung|desempenho|prestazioni|ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹|ì„±ëŠ¥|æ€§èƒ½|Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ)\b/iu,
    responses: {
      en: [
        "Here are the latest **BitNet benchmark results** on consumer hardware:\n\n### Performance Comparison\n| Model | Params | Tokens/s | RAM | Energy |\n|-------|--------|----------|-----|--------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n| Llama3-8B-1.58 | 8B | **15.03 t/s** | 4.2 GB | 5.8 mJ/tok |\n\n### Key Insights\n- ğŸ”‹ **71.4x** more energy efficient than FP16 equivalents\n- ğŸ’¾ **8-10x** smaller memory footprint\n- âš¡ Runs on **CPU only** â€” no GPU required\n- ğŸ“± Even the 2.4B model fits on most laptops\n\nAll benchmarks measured on a standard laptop CPU (Intel i7-12th gen, 16GB RAM).",
      ],
      fr: [
        "Voici les derniers **rÃ©sultats de benchmark BitNet** sur du matÃ©riel grand public :\n\n### Comparaison des performances\n| ModÃ¨le | Params | Tokens/s | RAM | Ã‰nergie |\n|--------|--------|----------|-----|--------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n| Llama3-8B-1.58 | 8B | **15.03 t/s** | 4.2 GB | 5.8 mJ/tok |\n\n### Points clÃ©s\n- ğŸ”‹ **71.4x** plus Ã©conome en Ã©nergie que les Ã©quivalents FP16\n- ğŸ’¾ **8-10x** moins d'empreinte mÃ©moire\n- âš¡ Fonctionne **uniquement sur CPU** â€” pas de GPU requis\n- ğŸ“± MÃªme le modÃ¨le 2.4B tient sur la plupart des laptops",
      ],
      es: [
        "AquÃ­ estÃ¡n los Ãºltimos **resultados de benchmark de BitNet** en hardware de consumo:\n\n### ComparaciÃ³n de rendimiento\n| Modelo | Params | Tokens/s | RAM | EnergÃ­a |\n|--------|--------|----------|-----|--------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n\n### Puntos clave\n- ğŸ”‹ **71.4x** mÃ¡s eficiente en energÃ­a que equivalentes FP16\n- ğŸ’¾ **8-10x** menor huella de memoria\n- âš¡ Funciona **solo en CPU** â€” no requiere GPU",
      ],
      de: [
        "Hier sind die neuesten **BitNet-Benchmark-Ergebnisse** auf Consumer-Hardware:\n\n### Leistungsvergleich\n| Modell | Params | Tokens/s | RAM | Energie |\n|--------|--------|----------|-----|--------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n\n### Wichtige Erkenntnisse\n- ğŸ”‹ **71.4x** energieeffizienter als FP16-Ã„quivalente\n- ğŸ’¾ **8-10x** kleinerer Speicherbedarf\n- âš¡ LÃ¤uft **nur auf CPU** â€” keine GPU erforderlich",
      ],
      pt: [
        "Aqui estÃ£o os Ãºltimos **resultados de benchmark do BitNet** em hardware de consumo:\n\n### ComparaÃ§Ã£o de desempenho\n| Modelo | Params | Tokens/s | RAM | Energia |\n|--------|--------|----------|-----|--------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n\n### Pontos-chave\n- ğŸ”‹ **71.4x** mais eficiente em energia que equivalentes FP16\n- ğŸ’¾ **8-10x** menor uso de memÃ³ria\n- âš¡ Funciona **apenas em CPU** â€” nÃ£o requer GPU",
      ],
      it: [
        "Ecco gli ultimi **risultati benchmark di BitNet** su hardware consumer:\n\n### Confronto prestazioni\n| Modello | Params | Tokens/s | RAM | Energia |\n|---------|--------|----------|-----|--------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n\n### Punti chiave\n- ğŸ”‹ **71.4x** piÃ¹ efficiente energeticamente rispetto a FP16\n- ğŸ’¾ **8-10x** minore impronta di memoria\n- âš¡ Funziona **solo su CPU** â€” nessuna GPU richiesta",
      ],
      ja: [
        "æ¶ˆè²»è€…å‘ã‘ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã®æœ€æ–°ã®**BitNetãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ**ï¼š\n\n### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ\n| ãƒ¢ãƒ‡ãƒ« | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ | RAM | ã‚¨ãƒãƒ«ã‚®ãƒ¼ |\n|--------|--------|----------|-----|--------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n\n### ä¸»ãªãƒã‚¤ãƒ³ãƒˆ\n- ğŸ”‹ FP16ã¨æ¯”è¼ƒã—ã¦**71.4å€**ã®ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡\n- ğŸ’¾ **8-10å€**å°ã•ã„ãƒ¡ãƒ¢ãƒªãƒ•ãƒƒãƒˆãƒ—ãƒªãƒ³ãƒˆ\n- âš¡ **CPUã®ã¿**ã§å‹•ä½œ â€” GPUã¯ä¸è¦",
      ],
      ko: [
        "ì†Œë¹„ì í•˜ë“œì›¨ì–´ì—ì„œì˜ ìµœì‹  **BitNet ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼**:\n\n### ì„±ëŠ¥ ë¹„êµ\n| ëª¨ë¸ | íŒŒë¼ë¯¸í„° | í† í°/ì´ˆ | RAM | ì—ë„ˆì§€ |\n|------|--------|---------|-----|--------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n\n### í•µì‹¬ í¬ì¸íŠ¸\n- ğŸ”‹ FP16 ëŒ€ë¹„ **71.4ë°°** ì—ë„ˆì§€ íš¨ìœ¨ì \n- ğŸ’¾ **8-10ë°°** ì‘ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰\n- âš¡ **CPUë§Œìœ¼ë¡œ** ì‹¤í–‰ â€” GPU ë¶ˆí•„ìš”",
      ],
      zh: [
        "ä»¥ä¸‹æ˜¯æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šçš„æœ€æ–°**BitNetåŸºå‡†æµ‹è¯•ç»“æœ**ï¼š\n\n### æ€§èƒ½æ¯”è¾ƒ\n| æ¨¡å‹ | å‚æ•° | ä»¤ç‰Œ/ç§’ | RAM | èƒ½è€— |\n|------|------|---------|-----|------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n\n### å…³é”®è¦ç‚¹\n- ğŸ”‹ æ¯”FP16**èŠ‚èƒ½71.4å€**\n- ğŸ’¾ å†…å­˜å ç”¨**å‡å°‘8-10å€**\n- âš¡ **ä»…éœ€CPU**è¿è¡Œ â€” æ— éœ€GPU",
      ],
      ru: [
        "Ğ’Ğ¾Ñ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ **Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¾Ğ² BitNet** Ğ½Ğ° Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ¸Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ¼ Ğ¾Ğ±Ğ¾Ñ€ÑƒĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸:\n\n### Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸\n| ĞœĞ¾Ğ´ĞµĞ»ÑŒ | ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ | Ğ¢Ğ¾ĞºĞµĞ½Ğ¾Ğ²/Ñ | RAM | Ğ­Ğ½ĞµÑ€Ğ³Ğ¸Ñ |\n|--------|-----------|-----------|-----|--------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n\n### ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹\n- ğŸ”‹ **Ğ’ 71.4 Ñ€Ğ°Ğ·Ğ°** ÑĞ½ĞµÑ€Ğ³Ğ¾ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½ĞµĞµ Ñ‡ĞµĞ¼ FP16\n- ğŸ’¾ **Ğ’ 8-10 Ñ€Ğ°Ğ·** Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ¹ Ğ¾Ğ±ÑŠĞµĞ¼ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸\n- âš¡ Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ **Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ° CPU** â€” GPU Ğ½Ğµ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ",
      ],
      ar: [
        "ÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ø£Ø­Ø¯Ø« **Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª BitNet** Ø¹Ù„Ù‰ Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ù„ÙƒÙŠÙ†:\n\n### Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡\n| Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª | Ø±Ù…Ø²/Ø«Ø§Ù†ÙŠØ© | RAM | Ø§Ù„Ø·Ø§Ù‚Ø© |\n|---------|----------|-----------|-----|--------|\n| BitNet-b1.58-large | 0.7B | **89.65** | 400 MB | 1.2 mJ |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94** | 1.3 GB | 2.4 mJ |\n\n### Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©\n- ğŸ”‹ ÙƒÙØ§Ø¡Ø© Ø·Ø§Ù‚Ø© Ø£Ø¹Ù„Ù‰ **71.4 Ù…Ø±Ø©** Ù…Ù† FP16\n- ğŸ’¾ **8-10 Ù…Ø±Ø§Øª** Ø£Ù‚Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©\n- âš¡ ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ **CPU ÙÙ‚Ø·** â€” Ù„Ø§ ÙŠØªØ·Ù„Ø¨ GPU",
      ],
      hi: [
        "à¤‰à¤ªà¤­à¥‹à¤•à¥à¤¤à¤¾ à¤¹à¤¾à¤°à¥à¤¡à¤µà¥‡à¤¯à¤° à¤ªà¤° à¤¨à¤µà¥€à¤¨à¤¤à¤® **BitNet à¤¬à¥‡à¤‚à¤šà¤®à¤¾à¤°à¥à¤• à¤ªà¤°à¤¿à¤£à¤¾à¤®**:\n\n### à¤ªà¥à¤°à¤¦à¤°à¥à¤¶à¤¨ à¤¤à¥à¤²à¤¨à¤¾\n| à¤®à¥‰à¤¡à¤² | à¤ªà¥ˆà¤°à¤¾à¤®à¥€à¤Ÿà¤° | à¤Ÿà¥‹à¤•à¤¨/à¤¸à¥‡à¤•à¤‚à¤¡ | RAM | à¤Šà¤°à¥à¤œà¤¾ |\n|-------|---------|------------|-----|-------|\n| BitNet-b1.58-large | 0.7B | **89.65 t/s** | 400 MB | 1.2 mJ/tok |\n| BitNet-b1.58-2B-4T | 2.4B | **36.94 t/s** | 1.3 GB | 2.4 mJ/tok |\n\n### à¤®à¥à¤–à¥à¤¯ à¤¬à¤¿à¤‚à¤¦à¥\n- ğŸ”‹ FP16 à¤•à¥€ à¤¤à¥à¤²à¤¨à¤¾ à¤®à¥‡à¤‚ **71.4x** à¤…à¤§à¤¿à¤• à¤Šà¤°à¥à¤œà¤¾ à¤•à¥à¤¶à¤²\n- ğŸ’¾ **8-10x** à¤•à¤® à¤®à¥‡à¤®à¥‹à¤°à¥€ à¤‰à¤ªà¤¯à¥‹à¤—\n- âš¡ **à¤•à¥‡à¤µà¤² CPU** à¤ªà¤° à¤šà¤²à¤¤à¤¾ à¤¹à¥ˆ â€” GPU à¤•à¥€ à¤†à¤µà¤¶à¥à¤¯à¤•à¤¤à¤¾ à¤¨à¤¹à¥€à¤‚",
      ],
    },
  },
  {
    // Help / capabilities
    pattern: /\b(help|what can|capable|feature|aide|ayuda|hilfe|ajuda|aiuto|ãƒ˜ãƒ«ãƒ—|ë„ì›€|å¸®åŠ©|Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ|Ù…Ø³Ø§Ø¹Ø¯Ø©|à¤®à¤¦à¤¦)\b/iu,
    responses: {
      en: [
        "Here's what I can help you with as your **local ARIA assistant**:\n\n### Knowledge Areas\n- **ARIA Protocol**: Architecture, roadmap, and features\n- **BitNet Models**: Performance, benchmarks, and optimization\n- **Decentralized AI**: Concepts, benefits, and comparisons\n- **Technical Topics**: 1-bit quantization, P2P networking, inference\n\n### Capabilities\n- ğŸ’¬ Natural conversation and Q&A\n- ğŸ“Š Performance data and benchmarks\n- ğŸ”§ Technical explanations\n- ğŸ’¡ Ideas and brainstorming\n\n### Important Notes\n- I run **100% locally** on your device\n- No data is sent to any server\n- Responses are generated by your local BitNet model\n- Speed depends on your hardware configuration",
      ],
      fr: [
        "Voici ce que je peux faire en tant que votre **assistant ARIA local** :\n\n### Domaines de connaissance\n- **Protocole ARIA** : Architecture, feuille de route et fonctionnalitÃ©s\n- **ModÃ¨les BitNet** : Performance, benchmarks et optimisation\n- **IA dÃ©centralisÃ©e** : Concepts, avantages et comparaisons\n- **Sujets techniques** : Quantification 1-bit, rÃ©seau P2P, infÃ©rence\n\n### CapacitÃ©s\n- ğŸ’¬ Conversation naturelle et Q&R\n- ğŸ“Š DonnÃ©es de performance et benchmarks\n- ğŸ”§ Explications techniques\n- ğŸ’¡ IdÃ©es et brainstorming\n\n### Notes importantes\n- Je fonctionne **100% localement** sur votre appareil\n- Aucune donnÃ©e n'est envoyÃ©e Ã  un serveur\n- La vitesse dÃ©pend de la configuration de votre matÃ©riel",
      ],
      es: [
        "Esto es lo que puedo ayudarte como tu **asistente ARIA local**:\n\n### Ãreas de conocimiento\n- **Protocolo ARIA**: Arquitectura, hoja de ruta y caracterÃ­sticas\n- **Modelos BitNet**: Rendimiento, benchmarks y optimizaciÃ³n\n- **IA descentralizada**: Conceptos, beneficios y comparaciones\n\n### Capacidades\n- ğŸ’¬ ConversaciÃ³n natural y preguntas\n- ğŸ“Š Datos de rendimiento y benchmarks\n- ğŸ”§ Explicaciones tÃ©cnicas\n- ğŸ’¡ Ideas y lluvia de ideas\n\n### Notas importantes\n- Funciono **100% localmente** en tu dispositivo\n- No se envÃ­an datos a ningÃºn servidor",
      ],
      de: [
        "Hier ist, womit ich dir als dein **lokaler ARIA-Assistent** helfen kann:\n\n### Wissensbereiche\n- **ARIA-Protokoll**: Architektur, Roadmap und Funktionen\n- **BitNet-Modelle**: Leistung, Benchmarks und Optimierung\n- **Dezentralisierte KI**: Konzepte, Vorteile und Vergleiche\n\n### FÃ¤higkeiten\n- ğŸ’¬ NatÃ¼rliche Konversation und Fragen\n- ğŸ“Š Leistungsdaten und Benchmarks\n- ğŸ”§ Technische ErklÃ¤rungen\n- ğŸ’¡ Ideen und Brainstorming\n\n### Wichtige Hinweise\n- Ich laufe **100% lokal** auf deinem GerÃ¤t\n- Keine Daten werden an Server gesendet",
      ],
      pt: [
        "Aqui estÃ¡ o que posso ajudÃ¡-lo como seu **assistente ARIA local**:\n\n### Ãreas de conhecimento\n- **Protocolo ARIA**: Arquitetura, roadmap e recursos\n- **Modelos BitNet**: Performance, benchmarks e otimizaÃ§Ã£o\n- **IA descentralizada**: Conceitos, benefÃ­cios e comparaÃ§Ãµes\n\n### Capacidades\n- ğŸ’¬ Conversa natural e perguntas\n- ğŸ“Š Dados de performance e benchmarks\n- ğŸ”§ ExplicaÃ§Ãµes tÃ©cnicas\n- ğŸ’¡ Ideias e brainstorming\n\n### Notas importantes\n- Funciono **100% localmente** no seu dispositivo\n- Nenhum dado Ã© enviado para servidores",
      ],
      it: [
        "Ecco come posso aiutarti come tuo **assistente ARIA locale**:\n\n### Aree di conoscenza\n- **Protocollo ARIA**: Architettura, roadmap e funzionalitÃ \n- **Modelli BitNet**: Prestazioni, benchmark e ottimizzazione\n- **IA decentralizzata**: Concetti, vantaggi e confronti\n\n### CapacitÃ \n- ğŸ’¬ Conversazione naturale e domande\n- ğŸ“Š Dati sulle prestazioni e benchmark\n- ğŸ”§ Spiegazioni tecniche\n- ğŸ’¡ Idee e brainstorming\n\n### Note importanti\n- Funziono **100% localmente** sul tuo dispositivo\n- Nessun dato viene inviato a server",
      ],
      ja: [
        "**ãƒ­ãƒ¼ã‚«ãƒ«ARIAã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ**ã¨ã—ã¦ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ï¼š\n\n### çŸ¥è­˜é ˜åŸŸ\n- **ARIAãƒ—ãƒ­ãƒˆã‚³ãƒ«**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã€æ©Ÿèƒ½\n- **BitNetãƒ¢ãƒ‡ãƒ«**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€æœ€é©åŒ–\n- **åˆ†æ•£å‹AI**: ã‚³ãƒ³ã‚»ãƒ—ãƒˆã€åˆ©ç‚¹ã€æ¯”è¼ƒ\n\n### æ©Ÿèƒ½\n- ğŸ’¬ è‡ªç„¶ãªä¼šè©±ã¨è³ªç–‘å¿œç­”\n- ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯\n- ğŸ”§ æŠ€è¡“çš„ãªèª¬æ˜\n- ğŸ’¡ ã‚¢ã‚¤ãƒ‡ã‚¢ã¨ãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°\n\n### é‡è¦ãªæ³¨æ„\n- ã‚ãªãŸã®ãƒ‡ãƒã‚¤ã‚¹ã§**100%ãƒ­ãƒ¼ã‚«ãƒ«**ã§å®Ÿè¡Œ\n- ãƒ‡ãƒ¼ã‚¿ã¯ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ã•ã‚Œã¾ã›ã‚“",
      ],
      ko: [
        "**ë¡œì»¬ ARIA ì–´ì‹œìŠ¤í„´íŠ¸**ë¡œì„œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆëŠ” ë¶„ì•¼:\n\n### ì§€ì‹ ì˜ì—­\n- **ARIA í”„ë¡œí† ì½œ**: ì•„í‚¤í…ì²˜, ë¡œë“œë§µ ë° ê¸°ëŠ¥\n- **BitNet ëª¨ë¸**: ì„±ëŠ¥, ë²¤ì¹˜ë§ˆí¬ ë° ìµœì í™”\n- **ë¶„ì‚°í˜• AI**: ê°œë…, ì´ì  ë° ë¹„êµ\n\n### ê¸°ëŠ¥\n- ğŸ’¬ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ë° ì§ˆë¬¸ ë‹µë³€\n- ğŸ“Š ì„±ëŠ¥ ë°ì´í„° ë° ë²¤ì¹˜ë§ˆí¬\n- ğŸ”§ ê¸°ìˆ ì  ì„¤ëª…\n- ğŸ’¡ ì•„ì´ë””ì–´ ë° ë¸Œë ˆì¸ìŠ¤í† ë°\n\n### ì¤‘ìš” ì‚¬í•­\n- ê·€í•˜ì˜ ê¸°ê¸°ì—ì„œ **100% ë¡œì»¬**ë¡œ ì‹¤í–‰\n- ì„œë²„ë¡œ ë°ì´í„°ê°€ ì „ì†¡ë˜ì§€ ì•ŠìŒ",
      ],
      zh: [
        "ä½œä¸ºæ‚¨çš„**æœ¬åœ°ARIAåŠ©æ‰‹**ï¼Œæˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š\n\n### çŸ¥è¯†é¢†åŸŸ\n- **ARIAåè®®**: æ¶æ„ã€è·¯çº¿å›¾å’ŒåŠŸèƒ½\n- **BitNetæ¨¡å‹**: æ€§èƒ½ã€åŸºå‡†æµ‹è¯•å’Œä¼˜åŒ–\n- **å»ä¸­å¿ƒåŒ–AI**: æ¦‚å¿µã€ä¼˜åŠ¿å’Œæ¯”è¾ƒ\n\n### åŠŸèƒ½\n- ğŸ’¬ è‡ªç„¶å¯¹è¯å’Œé—®ç­”\n- ğŸ“Š æ€§èƒ½æ•°æ®å’ŒåŸºå‡†æµ‹è¯•\n- ğŸ”§ æŠ€æœ¯è§£é‡Š\n- ğŸ’¡ åˆ›æ„å’Œå¤´è„‘é£æš´\n\n### é‡è¦è¯´æ˜\n- åœ¨æ‚¨çš„è®¾å¤‡ä¸Š**100%æœ¬åœ°**è¿è¡Œ\n- ä¸ä¼šå‘ä»»ä½•æœåŠ¡å™¨å‘é€æ•°æ®",
      ],
      ru: [
        "Ğ’Ğ¾Ñ‚ Ñ‡ĞµĞ¼ Ñ Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ ĞºĞ°Ğº Ğ²Ğ°Ñˆ **Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº ARIA**:\n\n### ĞĞ±Ğ»Ğ°ÑÑ‚Ğ¸ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹\n- **ĞŸÑ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ» ARIA**: ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°, Ğ´Ğ¾Ñ€Ğ¾Ğ¶Ğ½Ğ°Ñ ĞºĞ°Ñ€Ñ‚Ğ° Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸\n- **ĞœĞ¾Ğ´ĞµĞ»Ğ¸ BitNet**: ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ, Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¸ Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ\n- **Ğ”ĞµÑ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ˜Ğ˜**: ĞšĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ğ¸, Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ²Ğ° Ğ¸ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ\n\n### Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸\n- ğŸ’¬ Ğ•ÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€ Ğ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹\n- ğŸ“Š Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¾ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ±ĞµĞ½Ñ‡Ğ¼Ğ°Ñ€ĞºĞ¸\n- ğŸ”§ Ğ¢ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ñ\n- ğŸ’¡ Ğ˜Ğ´ĞµĞ¸ Ğ¸ Ğ¼Ğ¾Ğ·Ğ³Ğ¾Ğ²Ğ¾Ğ¹ ÑˆÑ‚ÑƒÑ€Ğ¼\n\n### Ğ’Ğ°Ğ¶Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ñ\n- Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ **100% Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾** Ğ½Ğ° Ğ²Ğ°ÑˆĞµĞ¼ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğµ\n- Ğ”Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ÑÑ Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€Ñ‹",
      ],
      ar: [
        "Ø¥Ù„ÙŠÙƒ Ù…Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¨Ù‡ ÙƒÙ€**Ù…Ø³Ø§Ø¹Ø¯ ARIA Ø§Ù„Ù…Ø­Ù„ÙŠ** Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ:\n\n### Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙØ©\n- **Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ ARIA**: Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ© ÙˆØ®Ø§Ø±Ø·Ø© Ø§Ù„Ø·Ø±ÙŠÙ‚ ÙˆØ§Ù„Ù…ÙŠØ²Ø§Øª\n- **Ù†Ù…Ø§Ø°Ø¬ BitNet**: Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†\n- **Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù„Ø§Ù…Ø±ÙƒØ²ÙŠ**: Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… ÙˆØ§Ù„ÙÙˆØ§Ø¦Ø¯ ÙˆØ§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª\n\n### Ø§Ù„Ù‚Ø¯Ø±Ø§Øª\n- ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ø·Ø¨ÙŠØ¹ÙŠØ© ÙˆØ£Ø³Ø¦Ù„Ø©\n- ğŸ“Š Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±\n- ğŸ”§ Ø´Ø±ÙˆØ­Ø§Øª ØªÙ‚Ù†ÙŠØ©\n- ğŸ’¡ Ø£ÙÙƒØ§Ø± ÙˆØ¹ØµÙ Ø°Ù‡Ù†ÙŠ\n\n### Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©\n- Ø£Ø¹Ù…Ù„ **100% Ù…Ø­Ù„ÙŠÙ‹Ø§** Ø¹Ù„Ù‰ Ø¬Ù‡Ø§Ø²Ùƒ\n- Ù„Ø§ ÙŠØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø£ÙŠ Ø®Ø§Ø¯Ù…",
      ],
      hi: [
        "à¤†à¤ªà¤•à¥‡ **à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ ARIA à¤¸à¤¹à¤¾à¤¯à¤•** à¤•à¥‡ à¤°à¥‚à¤ª à¤®à¥‡à¤‚ à¤®à¥ˆà¤‚ à¤‡à¤¨à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤:\n\n### à¤œà¥à¤à¤¾à¤¨ à¤•à¥à¤·à¥‡à¤¤à¥à¤°\n- **ARIA à¤ªà¥à¤°à¥‹à¤Ÿà¥‹à¤•à¥‰à¤²**: à¤†à¤°à¥à¤•à¤¿à¤Ÿà¥‡à¤•à¥à¤šà¤°, à¤°à¥‹à¤¡à¤®à¥ˆà¤ª à¤”à¤° à¤¸à¥à¤µà¤¿à¤§à¤¾à¤à¤‚\n- **BitNet à¤®à¥‰à¤¡à¤²**: à¤ªà¥à¤°à¤¦à¤°à¥à¤¶à¤¨, à¤¬à¥‡à¤‚à¤šà¤®à¤¾à¤°à¥à¤• à¤”à¤° à¤…à¤¨à¥à¤•à¥‚à¤²à¤¨\n- **à¤µà¤¿à¤•à¥‡à¤‚à¤¦à¥à¤°à¥€à¤•à¥ƒà¤¤ AI**: à¤…à¤µà¤§à¤¾à¤°à¤£à¤¾à¤à¤‚, à¤²à¤¾à¤­ à¤”à¤° à¤¤à¥à¤²à¤¨à¤¾\n\n### à¤•à¥à¤·à¤®à¤¤à¤¾à¤à¤‚\n- ğŸ’¬ à¤ªà¥à¤°à¤¾à¤•à¥ƒà¤¤à¤¿à¤• à¤¬à¤¾à¤¤à¤šà¥€à¤¤ à¤”à¤° à¤ªà¥à¤°à¤¶à¥à¤¨-à¤‰à¤¤à¥à¤¤à¤°\n- ğŸ“Š à¤ªà¥à¤°à¤¦à¤°à¥à¤¶à¤¨ à¤¡à¥‡à¤Ÿà¤¾ à¤”à¤° à¤¬à¥‡à¤‚à¤šà¤®à¤¾à¤°à¥à¤•\n- ğŸ”§ à¤¤à¤•à¤¨à¥€à¤•à¥€ à¤¸à¥à¤ªà¤·à¥à¤Ÿà¥€à¤•à¤°à¤£\n- ğŸ’¡ à¤µà¤¿à¤šà¤¾à¤° à¤”à¤° à¤®à¤‚à¤¥à¤¨\n\n### à¤®à¤¹à¤¤à¥à¤µà¤ªà¥‚à¤°à¥à¤£ à¤¨à¥‹à¤Ÿ\n- à¤†à¤ªà¤•à¥‡ à¤¡à¤¿à¤µà¤¾à¤‡à¤¸ à¤ªà¤° **100% à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯** à¤°à¥‚à¤ª à¤¸à¥‡ à¤šà¤²à¤¤à¤¾ à¤¹à¥ˆ\n- à¤•à¥‹à¤ˆ à¤¡à¥‡à¤Ÿà¤¾ à¤¸à¤°à¥à¤µà¤° à¤•à¥‹ à¤¨à¤¹à¥€à¤‚ à¤­à¥‡à¤œà¤¾ à¤œà¤¾à¤¤à¤¾",
      ],
    },
  },
];

// Default responses when no pattern matches
const defaultResponses: Record<SupportedLanguage, string[]> = {
  en: [
    "That's an interesting question! As a local AI running on ARIA Protocol with BitNet inference, I can share some thoughts.\n\nDecentralized AI is fundamentally about giving individuals control over their AI interactions. Unlike centralized services, everything here runs on your hardware â€” your data never leaves your device.\n\nWould you like to know more about how ARIA achieves this, or do you have a specific topic in mind?",
    "Great question! Let me think about that from the perspective of decentralized AI.\n\nOne of the key advantages of running models locally through ARIA is that we can have these conversations with **complete privacy**. No logs, no tracking, no data collection.\n\nThe BitNet model powering this conversation uses only ~1.3 GB of RAM and runs entirely on your CPU. That's the power of 1-bit quantization.\n\nIs there anything specific about ARIA or local AI you'd like to explore?",
    "I appreciate the question! Here's my take on it.\n\nThe shift toward **local AI inference** is one of the most significant trends in the AI space. Projects like ARIA Protocol are proving that you don't need massive data centers to run capable language models.\n\nWith BitNet's 1-bit architecture:\n- Models are **8-10x smaller** than traditional ones\n- Inference is **71x more energy efficient**\n- Everything runs on **consumer hardware**\n\nWhat else would you like to discuss?",
  ],
  fr: [
    "Excellente question ! En tant qu'IA locale fonctionnant sur le protocole ARIA avec l'infÃ©rence BitNet, voici mon point de vue.\n\nL'IA dÃ©centralisÃ©e consiste fondamentalement Ã  donner aux individus le contrÃ´le de leurs interactions avec l'IA. Contrairement aux services centralisÃ©s, tout fonctionne ici sur votre matÃ©riel â€” vos donnÃ©es ne quittent jamais votre appareil.\n\nVoulez-vous en savoir plus sur la faÃ§on dont ARIA rÃ©alise cela, ou avez-vous un sujet spÃ©cifique en tÃªte ?",
    "Bonne question ! Laissez-moi y rÃ©flÃ©chir du point de vue de l'IA dÃ©centralisÃ©e.\n\nL'un des principaux avantages de l'exÃ©cution de modÃ¨les localement via ARIA est que nous pouvons avoir ces conversations en **toute confidentialitÃ©**. Pas de journaux, pas de suivi, pas de collecte de donnÃ©es.\n\nLe modÃ¨le BitNet qui alimente cette conversation n'utilise que ~1.3 Go de RAM et fonctionne entiÃ¨rement sur votre CPU. C'est la puissance de la quantification 1-bit.\n\nY a-t-il quelque chose de spÃ©cifique sur ARIA ou l'IA locale que vous aimeriez explorer ?",
    "J'apprÃ©cie la question ! Voici mon avis.\n\nLe passage vers **l'infÃ©rence IA locale** est l'une des tendances les plus significatives dans l'espace IA. Des projets comme le protocole ARIA prouvent qu'il n'est pas nÃ©cessaire d'avoir des centres de donnÃ©es massifs pour exÃ©cuter des modÃ¨les de langage performants.\n\nAvec l'architecture 1-bit de BitNet :\n- Les modÃ¨les sont **8-10x plus petits** que les modÃ¨les traditionnels\n- L'infÃ©rence est **71x plus Ã©conome en Ã©nergie**\n- Tout fonctionne sur du **matÃ©riel grand public**\n\nDe quoi d'autre aimeriez-vous discuter ?",
  ],
  es: [
    "Â¡Excelente pregunta! Como IA local funcionando en el Protocolo ARIA con inferencia BitNet, puedo compartir algunas ideas.\n\nLa IA descentralizada se trata fundamentalmente de dar a los individuos control sobre sus interacciones con la IA. A diferencia de los servicios centralizados, todo aquÃ­ funciona en tu hardware â€” tus datos nunca salen de tu dispositivo.\n\nÂ¿Te gustarÃ­a saber mÃ¡s sobre cÃ³mo ARIA logra esto, o tienes algÃºn tema especÃ­fico en mente?",
    "Â¡Buena pregunta! DÃ©jame pensarlo desde la perspectiva de la IA descentralizada.\n\nUna de las principales ventajas de ejecutar modelos localmente a travÃ©s de ARIA es que podemos tener estas conversaciones con **completa privacidad**. Sin registros, sin seguimiento, sin recopilaciÃ³n de datos.\n\nEl modelo BitNet que impulsa esta conversaciÃ³n usa solo ~1.3 GB de RAM y funciona completamente en tu CPU.\n\nÂ¿Hay algo especÃ­fico sobre ARIA o la IA local que te gustarÃ­a explorar?",
  ],
  de: [
    "Interessante Frage! Als lokale KI, die auf dem ARIA-Protokoll mit BitNet-Inferenz lÃ¤uft, kann ich einige Gedanken teilen.\n\nDezentralisierte KI geht grundlegend darum, Einzelpersonen die Kontrolle Ã¼ber ihre KI-Interaktionen zu geben. Anders als bei zentralisierten Diensten lÃ¤uft hier alles auf deiner Hardware â€” deine Daten verlassen nie dein GerÃ¤t.\n\nMÃ¶chtest du mehr darÃ¼ber erfahren, wie ARIA das erreicht, oder hast du ein bestimmtes Thema im Sinn?",
    "Gute Frage! Lass mich das aus der Perspektive dezentralisierter KI betrachten.\n\nEiner der Hauptvorteile des lokalen AusfÃ¼hrens von Modellen Ã¼ber ARIA ist, dass wir diese GesprÃ¤che mit **vollstÃ¤ndiger PrivatsphÃ¤re** fÃ¼hren kÃ¶nnen. Keine Logs, kein Tracking, keine Datensammlung.\n\nDas BitNet-Modell, das dieses GesprÃ¤ch antreibt, verwendet nur ~1.3 GB RAM und lÃ¤uft vollstÃ¤ndig auf deiner CPU.\n\nGibt es etwas Bestimmtes Ã¼ber ARIA oder lokale KI, das du erkunden mÃ¶chtest?",
  ],
  pt: [
    "Excelente pergunta! Como uma IA local rodando no Protocolo ARIA com inferÃªncia BitNet, posso compartilhar algumas reflexÃµes.\n\nA IA descentralizada Ã© fundamentalmente sobre dar aos indivÃ­duos controle sobre suas interaÃ§Ãµes com IA. Diferente de serviÃ§os centralizados, tudo aqui roda no seu hardware â€” seus dados nunca saem do seu dispositivo.\n\nGostaria de saber mais sobre como o ARIA consegue isso, ou tem algum tÃ³pico especÃ­fico em mente?",
    "Boa pergunta! Deixe-me pensar nisso da perspectiva da IA descentralizada.\n\nUma das principais vantagens de rodar modelos localmente atravÃ©s do ARIA Ã© que podemos ter essas conversas com **total privacidade**. Sem logs, sem rastreamento, sem coleta de dados.\n\nO modelo BitNet que alimenta esta conversa usa apenas ~1.3 GB de RAM e roda inteiramente na sua CPU.\n\nHÃ¡ algo especÃ­fico sobre ARIA ou IA local que vocÃª gostaria de explorar?",
  ],
  it: [
    "Ottima domanda! Come IA locale che funziona sul Protocollo ARIA con inferenza BitNet, posso condividere alcuni pensieri.\n\nL'IA decentralizzata riguarda fondamentalmente il dare agli individui il controllo sulle loro interazioni con l'IA. A differenza dei servizi centralizzati, tutto qui funziona sul tuo hardware â€” i tuoi dati non lasciano mai il tuo dispositivo.\n\nVorresti saperne di piÃ¹ su come ARIA raggiunge questo, o hai un argomento specifico in mente?",
    "Buona domanda! Lasciami riflettere dal punto di vista dell'IA decentralizzata.\n\nUno dei principali vantaggi dell'esecuzione di modelli localmente tramite ARIA Ã¨ che possiamo avere queste conversazioni con **completa privacy**. Nessun log, nessun tracciamento, nessuna raccolta dati.\n\nIl modello BitNet che alimenta questa conversazione usa solo ~1.3 GB di RAM e funziona interamente sulla tua CPU.\n\nC'Ã¨ qualcosa di specifico su ARIA o sull'IA locale che vorresti esplorare?",
  ],
  ja: [
    "èˆˆå‘³æ·±ã„è³ªå•ã§ã™ã­ï¼BitNetæ¨è«–ã‚’ä½¿ç”¨ã—ã¦ARIAãƒ—ãƒ­ãƒˆã‚³ãƒ«ä¸Šã§å‹•ä½œã™ã‚‹ãƒ­ãƒ¼ã‚«ãƒ«AIã¨ã—ã¦ã€ã„ãã¤ã‹ã®è€ƒãˆã‚’å…±æœ‰ã§ãã¾ã™ã€‚\n\nåˆ†æ•£å‹AIã¯åŸºæœ¬çš„ã«ã€å€‹äººãŒAIã¨ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§ã™ã€‚ä¸­å¤®é›†æ¨©å‹ã‚µãƒ¼ãƒ“ã‚¹ã¨ã¯ç•°ãªã‚Šã€ã“ã“ã§ã¯ã™ã¹ã¦ãŒã‚ãªãŸã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ä¸Šã§å‹•ä½œã—ã¾ã™ â€” ãƒ‡ãƒ¼ã‚¿ã¯ãƒ‡ãƒã‚¤ã‚¹ã‚’é›¢ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n\nARIAãŒã“ã‚Œã‚’ã©ã®ã‚ˆã†ã«å®Ÿç¾ã—ã¦ã„ã‚‹ã‹ã«ã¤ã„ã¦ã‚‚ã£ã¨çŸ¥ã‚ŠãŸã„ã§ã™ã‹ã€ãã‚Œã¨ã‚‚ç‰¹å®šã®ãƒˆãƒ”ãƒƒã‚¯ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
    "è‰¯ã„è³ªå•ã§ã™ï¼åˆ†æ•£å‹AIã®è¦³ç‚¹ã‹ã‚‰è€ƒãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n\nARIAã‚’é€šã˜ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ä¸»ãªåˆ©ç‚¹ã®1ã¤ã¯ã€**å®Œå…¨ãªãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼**ã§ã“ã‚Œã‚‰ã®ä¼šè©±ãŒã§ãã‚‹ã“ã¨ã§ã™ã€‚ãƒ­ã‚°ãªã—ã€ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ãªã—ã€ãƒ‡ãƒ¼ã‚¿åé›†ãªã—ã€‚\n\nã“ã®ä¼šè©±ã‚’å‹•ã‹ã—ã¦ã„ã‚‹BitNetãƒ¢ãƒ‡ãƒ«ã¯ç´„1.3 GBã®RAMã—ã‹ä½¿ç”¨ã›ãšã€å®Œå…¨ã«CPUä¸Šã§å‹•ä½œã—ã¾ã™ã€‚\n\nARIAã‚„ãƒ­ãƒ¼ã‚«ãƒ«AIã«ã¤ã„ã¦æ¢æ±‚ã—ãŸã„ç‰¹å®šã®ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ",
  ],
  ko: [
    "í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ì…ë‹ˆë‹¤! BitNet ì¶”ë¡ ìœ¼ë¡œ ARIA í”„ë¡œí† ì½œì—ì„œ ì‹¤í–‰ë˜ëŠ” ë¡œì»¬ AIë¡œì„œ ëª‡ ê°€ì§€ ìƒê°ì„ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në¶„ì‚°í˜• AIëŠ” ê·¼ë³¸ì ìœ¼ë¡œ ê°œì¸ì´ AI ìƒí˜¸ì‘ìš©ì„ ì œì–´í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¤‘ì•™ ì§‘ì¤‘ì‹ ì„œë¹„ìŠ¤ì™€ ë‹¬ë¦¬, ì—¬ê¸°ì„œëŠ” ëª¨ë“  ê²ƒì´ ê·€í•˜ì˜ í•˜ë“œì›¨ì–´ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤ â€” ë°ì´í„°ëŠ” ì ˆëŒ€ ê¸°ê¸°ë¥¼ ë– ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n\nARIAê°€ ì´ë¥¼ ì–´ë–»ê²Œ ë‹¬ì„±í•˜ëŠ”ì§€ ë” ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”, ì•„ë‹ˆë©´ íŠ¹ì • ì£¼ì œê°€ ìˆìœ¼ì‹ ê°€ìš”?",
    "ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤! ë¶„ì‚°í˜• AIì˜ ê´€ì ì—ì„œ ìƒê°í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n\nARIAë¥¼ í†µí•´ ë¡œì»¬ì—ì„œ ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” ì£¼ìš” ì´ì  ì¤‘ í•˜ë‚˜ëŠ” **ì™„ì „í•œ í”„ë¼ì´ë²„ì‹œ**ë¡œ ì´ëŸ¬í•œ ëŒ€í™”ë¥¼ í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë¡œê·¸ ì—†ìŒ, ì¶”ì  ì—†ìŒ, ë°ì´í„° ìˆ˜ì§‘ ì—†ìŒ.\n\nì´ ëŒ€í™”ë¥¼ êµ¬ë™í•˜ëŠ” BitNet ëª¨ë¸ì€ ì•½ 1.3GB RAMë§Œ ì‚¬ìš©í•˜ê³  ì™„ì „íˆ CPUì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.\n\nARIAë‚˜ ë¡œì»¬ AIì— ëŒ€í•´ íƒêµ¬í•˜ê³  ì‹¶ì€ íŠ¹ì • ì‚¬í•­ì´ ìˆìœ¼ì‹ ê°€ìš”?",
  ],
  zh: [
    "è¿™æ˜¯ä¸ªæœ‰è¶£çš„é—®é¢˜ï¼ä½œä¸ºä½¿ç”¨BitNetæ¨ç†åœ¨ARIAåè®®ä¸Šè¿è¡Œçš„æœ¬åœ°AIï¼Œæˆ‘å¯ä»¥åˆ†äº«ä¸€äº›æƒ³æ³•ã€‚\n\nå»ä¸­å¿ƒåŒ–AIçš„æ ¸å¿ƒæ˜¯è®©ä¸ªäººæ§åˆ¶ä»–ä»¬ä¸AIçš„äº¤äº’ã€‚ä¸ä¸­å¿ƒåŒ–æœåŠ¡ä¸åŒï¼Œè¿™é‡Œçš„ä¸€åˆ‡éƒ½åœ¨æ‚¨çš„ç¡¬ä»¶ä¸Šè¿è¡Œâ€”â€”æ‚¨çš„æ•°æ®æ°¸è¿œä¸ä¼šç¦»å¼€æ‚¨çš„è®¾å¤‡ã€‚\n\næ‚¨æƒ³äº†è§£æ›´å¤šå…³äºARIAå¦‚ä½•å®ç°è¿™ä¸€ç‚¹çš„ä¿¡æ¯ï¼Œè¿˜æ˜¯æœ‰ç‰¹å®šçš„è¯é¢˜æƒ³è®¨è®ºï¼Ÿ",
    "å¥½é—®é¢˜ï¼è®©æˆ‘ä»å»ä¸­å¿ƒåŒ–AIçš„è§’åº¦æ¥æ€è€ƒã€‚\n\né€šè¿‡ARIAæœ¬åœ°è¿è¡Œæ¨¡å‹çš„ä¸»è¦ä¼˜åŠ¿ä¹‹ä¸€æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨**å®Œå…¨éšç§**çš„æƒ…å†µä¸‹è¿›è¡Œè¿™äº›å¯¹è¯ã€‚æ²¡æœ‰æ—¥å¿—ï¼Œæ²¡æœ‰è·Ÿè¸ªï¼Œæ²¡æœ‰æ•°æ®æ”¶é›†ã€‚\n\né©±åŠ¨è¿™æ¬¡å¯¹è¯çš„BitNetæ¨¡å‹åªä½¿ç”¨çº¦1.3 GB RAMï¼Œå®Œå…¨åœ¨æ‚¨çš„CPUä¸Šè¿è¡Œã€‚\n\næœ‰ä»€ä¹ˆå…³äºARIAæˆ–æœ¬åœ°AIçš„ç‰¹å®šå†…å®¹æ‚¨æƒ³æ¢ç´¢å—ï¼Ÿ",
  ],
  ru: [
    "Ğ˜Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ñ‹Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ! ĞšĞ°Ğº Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ˜Ğ˜, Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ‚Ğ¾ĞºĞ¾Ğ»Ğµ ARIA Ñ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ¾Ğ¼ BitNet, Ğ¼Ğ¾Ğ³Ñƒ Ğ¿Ğ¾Ğ´ĞµĞ»Ğ¸Ñ‚ÑŒÑÑ Ğ½ĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¼Ğ¸ Ğ¼Ñ‹ÑĞ»ÑĞ¼Ğ¸.\n\nĞ”ĞµÑ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ˜Ğ˜ â€” ÑÑ‚Ğ¾ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¾ Ñ‚Ğ¾Ğ¼, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ´Ğ°Ñ‚ÑŒ Ğ»ÑĞ´ÑĞ¼ ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ½Ğ°Ğ´ Ğ¸Ñ… Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸ĞµĞ¼ Ñ Ğ˜Ğ˜. Ğ’ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¾Ñ‚ Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ², Ğ·Ğ´ĞµÑÑŒ Ğ²ÑÑ‘ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° Ğ²Ğ°ÑˆĞµĞ¼ Ğ¾Ğ±Ğ¾Ñ€ÑƒĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ â€” Ğ²Ğ°ÑˆĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ¸ĞºĞ¾Ğ³Ğ´Ğ° Ğ½Ğµ Ğ¿Ğ¾ĞºĞ¸Ğ´Ğ°ÑÑ‚ Ğ²Ğ°ÑˆĞµ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ¾.\n\nĞ¥Ğ¾Ñ‚Ğ¸Ñ‚Ğµ ÑƒĞ·Ğ½Ğ°Ñ‚ÑŒ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ¾ Ñ‚Ğ¾Ğ¼, ĞºĞ°Ğº ARIA Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ°ĞµÑ‚ ÑÑ‚Ğ¾Ğ³Ğ¾, Ğ¸Ğ»Ğ¸ Ñƒ Ğ²Ğ°Ñ ĞµÑÑ‚ÑŒ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ°Ñ Ñ‚ĞµĞ¼Ğ°?",
    "Ğ¥Ğ¾Ñ€Ğ¾ÑˆĞ¸Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ! ĞŸĞ¾Ğ·Ğ²Ğ¾Ğ»ÑŒÑ‚Ğµ Ğ¼Ğ½Ğµ Ğ¿Ğ¾Ğ´ÑƒĞ¼Ğ°Ñ‚ÑŒ Ğ¾Ğ± ÑÑ‚Ğ¾Ğ¼ Ñ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ·Ñ€ĞµĞ½Ğ¸Ñ Ğ´ĞµÑ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ˜Ğ˜.\n\nĞĞ´Ğ½Ğ¾ Ğ¸Ğ· ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ñ… Ğ¿Ñ€ĞµĞ¸Ğ¼ÑƒÑ‰ĞµÑÑ‚Ğ² Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ‡ĞµÑ€ĞµĞ· ARIA â€” Ğ¼Ñ‹ Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ²ĞµÑÑ‚Ğ¸ ÑÑ‚Ğ¸ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ñ‹ Ñ **Ğ¿Ğ¾Ğ»Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ´ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒÑ**. ĞĞ¸ĞºĞ°ĞºĞ¸Ñ… Ğ»Ğ¾Ğ³Ğ¾Ğ², Ğ½Ğ¸ĞºĞ°ĞºĞ¾Ğ³Ğ¾ Ğ¾Ñ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ, Ğ½Ğ¸ĞºĞ°ĞºĞ¾Ğ³Ğ¾ ÑĞ±Ğ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….\n\nĞœĞ¾Ğ´ĞµĞ»ÑŒ BitNet, Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ÑÑ‰Ğ°Ñ ÑÑ‚Ğ¾Ñ‚ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ²ÑĞµĞ³Ğ¾ ~1.3 Ğ“Ğ‘ ĞĞ—Ğ£ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ğ½Ğ° Ğ²Ğ°ÑˆĞµĞ¼ CPU.\n\nĞ•ÑÑ‚ÑŒ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğµ Ğ¾Ğ± ARIA Ğ¸Ğ»Ğ¸ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ˜Ğ˜, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ñ…Ğ¾Ñ‚ĞµĞ»Ğ¸ Ğ±Ñ‹ Ğ¸Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ?",
  ],
  ar: [
    "Ø³Ø¤Ø§Ù„ Ù…Ø«ÙŠØ± Ù„Ù„Ø§Ù‡ØªÙ…Ø§Ù…! ÙƒØ°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø­Ù„ÙŠ ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ ARIA Ù…Ø¹ Ø§Ø³ØªØ¯Ù„Ø§Ù„ BitNetØŒ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø´Ø§Ø±ÙƒØ© Ø¨Ø¹Ø¶ Ø§Ù„Ø£ÙÙƒØ§Ø±.\n\nØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù„Ø§Ù…Ø±ÙƒØ²ÙŠ ÙŠØªØ¹Ù„Ù‚ Ø£Ø³Ø§Ø³Ù‹Ø§ Ø¨Ù…Ù†Ø­ Ø§Ù„Ø£ÙØ±Ø§Ø¯ Ø§Ù„Ø³ÙŠØ·Ø±Ø© Ø¹Ù„Ù‰ ØªÙØ§Ø¹Ù„Ø§ØªÙ‡Ù… Ù…Ø¹ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. Ø¹Ù„Ù‰ Ø¹ÙƒØ³ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©ØŒ ÙƒÙ„ Ø´ÙŠØ¡ Ù‡Ù†Ø§ ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø£Ø¬Ù‡Ø²ØªÙƒ â€” Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ù„Ø§ ØªØºØ§Ø¯Ø± Ø¬Ù‡Ø§Ø²Ùƒ Ø£Ø¨Ø¯Ù‹Ø§.\n\nÙ‡Ù„ ØªØ±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø¹Ù† ÙƒÙŠÙÙŠØ© ØªØ­Ù‚ÙŠÙ‚ ARIA Ù„Ù‡Ø°Ø§ØŒ Ø£Ù… Ù„Ø¯ÙŠÙƒ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø­Ø¯Ø¯ ÙÙŠ Ø°Ù‡Ù†ÙƒØŸ",
  ],
  hi: [
    "à¤¦à¤¿à¤²à¤šà¤¸à¥à¤ª à¤¸à¤µà¤¾à¤²! BitNet à¤…à¤¨à¥à¤®à¤¾à¤¨ à¤•à¥‡ à¤¸à¤¾à¤¥ ARIA à¤ªà¥à¤°à¥‹à¤Ÿà¥‹à¤•à¥‰à¤² à¤ªà¤° à¤šà¤²à¤¨à¥‡ à¤µà¤¾à¤²à¥‡ à¤¸à¥à¤¥à¤¾à¤¨à¥€à¤¯ AI à¤•à¥‡ à¤°à¥‚à¤ª à¤®à¥‡à¤‚, à¤®à¥ˆà¤‚ à¤•à¥à¤› à¤µà¤¿à¤šà¤¾à¤° à¤¸à¤¾à¤à¤¾ à¤•à¤° à¤¸à¤•à¤¤à¤¾ à¤¹à¥‚à¤à¥¤\n\nà¤µà¤¿à¤•à¥‡à¤‚à¤¦à¥à¤°à¥€à¤•à¥ƒà¤¤ AI à¤®à¥‚à¤² à¤°à¥‚à¤ª à¤¸à¥‡ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤¯à¥‹à¤‚ à¤•à¥‹ à¤‰à¤¨à¤•à¥‡ AI à¤‡à¤‚à¤Ÿà¤°à¥ˆà¤•à¥à¤¶à¤¨ à¤ªà¤° à¤¨à¤¿à¤¯à¤‚à¤¤à¥à¤°à¤£ à¤¦à¥‡à¤¨à¥‡ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¹à¥ˆà¥¤ à¤•à¥‡à¤‚à¤¦à¥à¤°à¥€à¤•à¥ƒà¤¤ à¤¸à¥‡à¤µà¤¾à¤“à¤‚ à¤•à¥‡ à¤µà¤¿à¤ªà¤°à¥€à¤¤, à¤¯à¤¹à¤¾à¤ à¤¸à¤¬ à¤•à¥à¤› à¤†à¤ªà¤•à¥‡ à¤¹à¤¾à¤°à¥à¤¡à¤µà¥‡à¤¯à¤° à¤ªà¤° à¤šà¤²à¤¤à¤¾ à¤¹à¥ˆ â€” à¤†à¤ªà¤•à¤¾ à¤¡à¥‡à¤Ÿà¤¾ à¤•à¤­à¥€ à¤­à¥€ à¤†à¤ªà¤•à¥‡ à¤¡à¤¿à¤µà¤¾à¤‡à¤¸ à¤•à¥‹ à¤¨à¤¹à¥€à¤‚ à¤›à¥‹à¤¡à¤¼à¤¤à¤¾à¥¤\n\nà¤•à¥à¤¯à¤¾ à¤†à¤ª à¤œà¤¾à¤¨à¤¨à¤¾ à¤šà¤¾à¤¹à¥‡à¤‚à¤—à¥‡ à¤•à¤¿ ARIA à¤¯à¤¹ à¤•à¥ˆà¤¸à¥‡ à¤ªà¥à¤°à¤¾à¤ªà¥à¤¤ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆ, à¤¯à¤¾ à¤†à¤ªà¤•à¥‡ à¤®à¤¨ à¤®à¥‡à¤‚ à¤•à¥‹à¤ˆ à¤µà¤¿à¤¶à¤¿à¤·à¥à¤Ÿ à¤µà¤¿à¤·à¤¯ à¤¹à¥ˆ?",
  ],
};

export function getMockResponse(prompt: string): string {
  const lang = detectLanguage(prompt);
  const lowerPrompt = prompt.toLowerCase();

  for (const mock of mockResponses) {
    if (mock.pattern.test(lowerPrompt)) {
      const langResponses = mock.responses[lang] || mock.responses["en"];
      const idx = Math.floor(Math.random() * langResponses.length);
      return langResponses[idx];
    }
  }

  const langDefaults = defaultResponses[lang] || defaultResponses["en"];
  const idx = Math.floor(Math.random() * langDefaults.length);
  return langDefaults[idx];
}

export function generateTitle(firstMessage: string): string {
  const cleaned = firstMessage.trim().slice(0, 60);

  if (
    /\b(hello|hi|hey|bonjour|salut|hola|hallo|olÃ¡|ciao|ã“ã‚“ã«ã¡ã¯|ì•ˆë…•|ä½ å¥½|Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚|Ù…Ø±Ø­Ø¨Ø§|à¤¨à¤®à¤¸à¥à¤¤à¥‡)\b/iu.test(
      cleaned
    )
  ) {
    return "New conversation";
  }

  const sentence = cleaned.split(/[.!?]/)[0].trim();
  if (sentence.length > 40) {
    return sentence.slice(0, 40) + "...";
  }
  return sentence || "New conversation";
}
